{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output all code in a chunk\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# importing required libraries and functions\n",
    "\n",
    "# data exploration\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "# text mining\n",
    "import re # regular expression\n",
    "from nltk import word_tokenize, PorterStemmer # natural language toolkit\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "## from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# modeling building\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "# download nltk packages\n",
    "# nltk.download()\n",
    "\n",
    "# working directory\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading data\n",
    "train = pd.read_csv(\"train.csv\", nrows = 10000)\n",
    "test = pd.read_csv(\"test.csv\", nrows = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "49f6b26a-9b0d-4b17-9541-07499497bf75",
    "_uuid": "5314745d9591b2f4d78ce2f0b5de47c26268a8ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    Yo bitch Ja Rule is more succesful then you'll...\n",
       "1    == From RfC == \\n\\n The title is fine as it is...\n",
       "2    \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3    :If you have a look back at the source, the in...\n",
       "4            I don't anonymously edit articles at all.\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying data\n",
    "train.comment_text.head()\n",
    "test.comment_text.head()\n",
    "len(train)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train.comment_text, train.iloc[:,2:8], test_size=0.3, random_state=19)\n",
    "X_test = test.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating function to normalize text\n",
    "def normalize(text):\n",
    "    # recognizing new line characters and tab spaces and substituting it with space\n",
    "    norm_text = re.sub(r'\\n|\\t', ' ', text)\n",
    "    # recognizing time values\n",
    "    norm_text = re.sub(r'[0-9]{1,2}:[0-9][0-9]', 'time_value', norm_text) # example 5:13pm and 05:13pm\n",
    "    # recognizing date values\n",
    "    norm_text = re.sub(r'\\d{1,4}[-/]\\d{1,2}[-/]\\d{1,4}', 'date_value', norm_text) # example 2018-03/05 and 04/03-2018\n",
    "    norm_text = re.sub(r'[0-9]{1,4}[ ,][A-Za-z]{3,10}[ ,][0-9]{1,4}', 'date_value', norm_text) # example 9 june 2009 and 9 June 2009\n",
    "    # substitute characters not required by nothing, removing unrequired characters\n",
    "    norm_text = re.sub(r'[^A-Za-z_ ]', ' ', norm_text)\n",
    "    # removing multiple space values\n",
    "    norm_text = re.sub(r' +', ' ', norm_text)\n",
    "    # removing trailing spaces from front and back and converting all text to lowercase\n",
    "    norm_text = norm_text.strip().lower()\n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating stemmer object of PorterStemmer function\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# writing stem_tokens function to perform stemming on tokens\n",
    "def stem_tokens(tokens, stemmer): # tokens example: ['today', 'is', 'a', 'good', 'day']\n",
    "    stemmed = [stemmer.stem(word) for word in tokens]\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# processing text as follows\n",
    "# tokenize words in each comment\n",
    "# remove stopwords or words upto lenght of 3 characters\n",
    "# stem words using the stem_tokens function we created above\n",
    "def text_process(text): # text is a single sentence; for example: 'today is a good day'\n",
    "    temp_tokens = word_tokenize(text)\n",
    "\n",
    "    # using alternative to removing stopwords of english\n",
    "    ## tokens = [word for word in temp_tokens if len(word) > 3]\n",
    "    \n",
    "    # removing english stopwords, code was commented to save computation time\n",
    "    nostop_tokens = [word for word in temp_tokens if word not in stopwords.words('english')]\n",
    "    \n",
    "    stems = stem_tokens(nostop_tokens, stemmer)\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lenght of stopword of english\n",
    "len(stopwords.words('english'))\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing training text to pass in count vectorizer\n",
    "corpus = []\n",
    "for text in X_train:\n",
    "    text = normalize(text)\n",
    "    text = text_process(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build Count Vectorizer, to convert a collection of text documents to a matrix of token counts\n",
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "X_train_counts = count_vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build TFIDF Transformer, to transform a count matrix to a normalized tf or tf-idf representation\n",
    "# tfidf - term frequency inverse document frequency\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verifing data\n",
    "# print(X_train_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verifing data\n",
    "# print(X_train_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  After  \\\n",
      "8098  edit anthoni hungerford dear phillip comment r...   \n",
      "3382  welcom wikipedia pleas stop insert unsourc lib...   \n",
      "5286                ye red link meet mo dabrl see chang   \n",
      "3693  hello submiss utrecht te deum jubil know nomin...   \n",
      "9616  song adapt worth song iron maiden movi heart d...   \n",
      "1818  lol lol serious bryanfrompalatin ip resolv col...   \n",
      "3687  thank welcom thank tom warm welcom see path cr...   \n",
      "3791  thank moonriddengirl wikidea sure excel lawyer...   \n",
      "6176  also tag page vkurka cur prev time_valu date_v...   \n",
      "925   wikipedia full fool take money make peopl work...   \n",
      "\n",
      "                                                 Before  \n",
      "8098  \"\\n\\n Editing of Anthony Hungerford \\n\\nDear P...  \n",
      "3382  Welcome to Wikipedia. Please stop inserting un...  \n",
      "5286  Yes, it was a red link which didn't meet MOS:D...  \n",
      "3693  Hello! Your submission of Utrecht Te Deum and ...  \n",
      "9616  \"\\n\\nsong adaptation\\nfor what it worthes ther...  \n",
      "1818  \"\\n\\n LOL \\n\\nLOL. Seriously, \"\"BryanFromPalat...  \n",
      "3687  Thanks for the welcome \\n\\nThanks Tom for the ...  \n",
      "3791  Thanks Moonriddengirl. Wikidea, I'm sure you'r...  \n",
      "6176  You also tagged my page, vkurka. (cur | prev) ...  \n",
      "925   Wikipedia is full of fools. Who takes money an...  \n"
     ]
    }
   ],
   "source": [
    "# checking how much text is transformed\n",
    "temp = pd.DataFrame({'Before': X_train, 'After': corpus})\n",
    "print(temp.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing validation text to pass in count vectorizer\n",
    "X_val_set = []\n",
    "for text in X_val:\n",
    "    text = normalize(text)\n",
    "    text = text_process(text)\n",
    "    X_val_set.append(text)\n",
    "\n",
    "# tranforming validation data using count vectorizer followed by tfidf transformer\n",
    "X_val_counts = count_vect.transform(X_val_set)\n",
    "X_val_tfidf = tfidf_transformer.transform(X_val_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing test text to pass in count vectorizer\n",
    "X_test_set = []\n",
    "for text in X_test:\n",
    "    text = normalize(text)\n",
    "    text = text_process(text)\n",
    "    X_test_set.append(text)\n",
    "\n",
    "# tranforming validation data using count vectorizer followed by tfidf transformer\n",
    "X_test_counts = count_vect.transform(X_test_set)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Singular Value Decomposition\n",
    "# Commented as using SVD decreased the estimation score\n",
    "# build Truncated SVD to reduce the dimensionality\n",
    "\n",
    "## svd=TruncatedSVD(n_components=100)\n",
    "## X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "## X_val_svd = svd.transform(X_val_tfidf)\n",
    "## X_test_svd = svd.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating dictionary to store prediction results\n",
    "result_test = dict()\n",
    "result_val = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__alpha': [0.001, 0.01, 0.1, 1.0, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of Multinomial Naive Bayes Classifier on Training Data: 1.000\n",
      "Accurary of Multinomial Naive Bayes Classifier on Validation Data: 0.825\n",
      "Grid best parameter (max. accuracy):  {'estimator__alpha': 0.1}\n",
      "Grid best score (accuracy):  0.848985648234\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes Model\n",
    "MNB_classifier = OneVsRestClassifier(MultinomialNB())\n",
    "grid_values = {'estimator__alpha': [0.001, 0.01, 0.1, 1.0, 10, 100]}\n",
    "MNB_model = GridSearchCV(MNB_classifier, param_grid = grid_values, scoring = 'roc_auc')\n",
    "MNB_model.fit(X_train_tfidf, y_train)\n",
    "print('Accurary of Multinomial Naive Bayes Classifier on Training Data: {:.3f}' .format(MNB_model.score(X_train_tfidf, y_train)))\n",
    "print('Accurary of Multinomial Naive Bayes Classifier on Validation Data: {:.3f}' .format(MNB_model.score(X_val_tfidf, y_val)))\n",
    "print('Grid best parameter (max. accuracy): ', MNB_model.best_params_)\n",
    "print('Grid best score (accuracy): ', MNB_model.best_score_)\n",
    "result_test['Multinomial_NB'] = MNB_model.predict(X_test_tfidf)\n",
    "result_val['Multinomial_NB'] = MNB_model.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([376,   0, 133,   0,  53,   0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial_NB result summary\n",
    "result_test['Multinomial_NB'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__alpha': [0.001, 0.01, 0.1, 1.0, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of Bernoulli Naive Bayes Classifier on Training Data: 1.000\n",
      "Accurary of Bernoulli Naive Bayes Classifier on Validation Data: 0.814\n",
      "Grid best parameter (max. accuracy):  {'estimator__alpha': 0.001}\n",
      "Grid best score (accuracy):  0.815762586966\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes Model\n",
    "BNB_classifier = OneVsRestClassifier(BernoulliNB())\n",
    "grid_values = {'estimator__alpha': [0.001, 0.01, 0.1, 1.0, 10, 100]}\n",
    "BNB_model = GridSearchCV(BNB_classifier, param_grid = grid_values, scoring = 'roc_auc')\n",
    "BNB_model.fit(X_train_tfidf, y_train)\n",
    "print('Accurary of Bernoulli Naive Bayes Classifier on Training Data: {:.3f}' .format(BNB_model.score(X_train_tfidf, y_train)))\n",
    "print('Accurary of Bernoulli Naive Bayes Classifier on Validation Data: {:.3f}' .format(BNB_model.score(X_val_tfidf, y_val)))\n",
    "print('Grid best parameter (max. accuracy): ', BNB_model.best_params_)\n",
    "print('Grid best score (accuracy): ', BNB_model.best_score_)\n",
    "result_test['Bernoulli_NB'] = BNB_model.predict(X_test_tfidf)\n",
    "result_val['Bernoulli_NB'] = BNB_model.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3770, 2457, 3265, 2089, 3453, 2447])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernoulli_NB result summary\n",
    "result_test['Bernoulli_NB'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__C': [0.3, 1.0, 30.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of Logistic Regression Classifier on Training Data: 1.000\n",
      "Accurary of Logistic Regression Classifier on Validation Data: 0.971\n",
      "Grid best parameter (max. accuracy):  {'estimator__C': 30.0}\n",
      "Grid best score (accuracy):  0.953124843436\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "log_model = OneVsRestClassifier(LogisticRegression())\n",
    "#log_model.get_params().keys()\n",
    "grid_values = {'estimator__C': [0.3, 1.0, 30.0]}\n",
    "log_grid = GridSearchCV(log_model, param_grid = grid_values, scoring = 'roc_auc')\n",
    "log_grid.fit(X_train_tfidf, y_train)\n",
    "print('Accurary of Logistic Regression Classifier on Training Data: {:.3f}' .format(log_grid.score(X_train_tfidf, y_train)))\n",
    "print('Accurary of Logistic Regression Classifier on Validation Data: {:.3f}' .format(log_grid.score(X_val_tfidf, y_val)))\n",
    "print('Grid best parameter (max. accuracy): ', log_grid.best_params_)\n",
    "print('Grid best score (accuracy): ', log_grid.best_score_)\n",
    "result_test['Logistic_Regression'] = log_grid.predict(X_test_tfidf)\n",
    "result_val['Logistic_Regression'] = log_grid.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1269,   83,  712,    1,  663,   59])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic_Regression result summary\n",
    "result_test['Logistic_Regression'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__C': [0.3, 1.0, 30.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of SVM Classifier on Training Data: 1.000\n",
      "Accurary of SVM Classifier on Validation Data: 0.953\n",
      "Grid best parameter (max. accuracy):  {'estimator__C': 0.3}\n",
      "Grid best score (accuracy):  0.939056090018\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier Model\n",
    "grid_values = {'estimator__C': [0.3, 1.0, 30.0]}\n",
    "svm_model = OneVsRestClassifier(SVC(kernel = 'linear'))\n",
    "svm_grid = GridSearchCV(svm_model, param_grid = grid_values, scoring = 'roc_auc')\n",
    "svm_grid.fit(X_train_tfidf, y_train)\n",
    "print('Accurary of SVM Classifier on Training Data: {:.3f}' .format(svm_grid.score(X_train_tfidf, y_train)))\n",
    "print('Accurary of SVM Classifier on Validation Data: {:.3f}' .format(svm_grid.score(X_val_tfidf, y_val)))\n",
    "print('Grid best parameter (max. accuracy): ', svm_grid.best_params_)\n",
    "print('Grid best score (accuracy): ', svm_grid.best_score_)\n",
    "result_test['SVM_Classifier'] = svm_grid.predict(X_test_tfidf)\n",
    "result_val['SVM_Classifier'] = svm_grid.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([592,   0, 455,   0, 304,   0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM_Classifier result summary\n",
    "result_test['SVM_Classifier'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Toxic Cases using Multinomial Naive Bayes Model: 562.00\n",
      "Number of Toxic Cases using Bernoulli Naive Bayes Model: 17481.00\n",
      "Number of Toxic Cases using Logistic Regression Classifier Model: 2787.00\n",
      "Number of Toxic Cases using SVM Classifier Model: 1351.00\n",
      "\n",
      "Total Number of Comments for which we made Predictions: 10000.00\n",
      "\n",
      "Total Number of Positive Cases in Training Data (Training + Validation): 2210.00\n",
      "Total Number of Comments in Training Data (Training + Validation): 10000.00\n",
      "Number of Toxic Cases using SVM Classifier Model: 406.00\n"
     ]
    }
   ],
   "source": [
    "# how many positive cases, i.e toxic cases we recognized for each model?\n",
    "print('Number of Toxic Cases using Multinomial Naive Bayes Model: {:.2f}' .format(result_test['Multinomial_NB'].sum()))\n",
    "print('Number of Toxic Cases using Bernoulli Naive Bayes Model: {:.2f}' .format(result_test['Bernoulli_NB'].sum()))\n",
    "print('Number of Toxic Cases using Logistic Regression Classifier Model: {:.2f}' .format(result_test['Logistic_Regression'].sum()))\n",
    "print('Number of Toxic Cases using SVM Classifier Model: {:.2f}' .format(result_test['SVM_Classifier'].sum()))\n",
    "\n",
    "# predicted for how many comments?\n",
    "print('\\nTotal Number of Comments for which we made Predictions: {:.2f}' .format(len(X_test)))\n",
    "\n",
    "# number of positive cases in training data and length of training data, includes validation data\n",
    "print('\\nTotal Number of Positive Cases in Training Data (Training + Validation): {:.2f}' .format(train.iloc[:,2:8].sum(axis=0).sum()))\n",
    "print('Total Number of Comments in Training Data (Training + Validation): {:.2f}' .format(len(X_train)+len(X_val)))\n",
    "\n",
    "# number of predicted positive cases in training data using SVM model\n",
    "print('Number of Toxic Cases using SVM Classifier Model: {:.2f}' .format(svm_grid.predict(X_train_tfidf).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing results of SVM Classifier as our result\n",
    "y_test = result_test['SVM_Classifier']\n",
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...      1   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...      0   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...      0   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...      0   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining final results with the original test data set\n",
    "output = pd.DataFrame(y_test, columns = train.columns[2:8], index = test.index)\n",
    "output = pd.concat([test, output], axis=1)\n",
    "\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifing data\n",
    "X_train_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-78bdc2795467>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# verifing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;31m##############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# verifing data\n",
    "X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifing data\n",
    "output.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifing select random case, as per index from above code chunk\n",
    "output.iloc[5902,:]\n",
    "output.comment_text[5902]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifing data\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick summary for training, validation and test set respectively\n",
    "# this shows the balance in results using SVM model in comparison to training data\n",
    "y_train.sum(axis=0)\n",
    "y_val.sum(axis=0)\n",
    "output.iloc[:,2:8].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision recall f1-score report\n",
    "print(metrics.classification_report(y_val.toxic, result_val['Multinomial_NB'][:,1], target_names = [\"positive\", \"negative\"]))\n",
    "print(metrics.classification_report(y_val.toxic, result_val['Bernoulli_NB'][:,1], target_names = [\"positive\", \"negative\"]))\n",
    "print(metrics.classification_report(y_val.toxic, result_val['Logistic_Regression'][:,1], target_names = [\"positive\", \"negative\"]))\n",
    "print(metrics.classification_report(y_val.toxic, result_val['SVM_Classifier'][:,1], target_names = [\"positive\", \"negative\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a object with final output of predictions on the test data set\n",
    "final_output = output.drop(['comment_text'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing the output object to a csv file\n",
    "final_output.to_csv('submission_project.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
