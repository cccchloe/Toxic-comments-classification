{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output all code in a chunk\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# importing required libraries and functions\n",
    "\n",
    "# data exploration\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "# text mining\n",
    "import re # regular expression\n",
    "from nltk import word_tokenize, PorterStemmer # natural language toolkit\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "## from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# modeling building\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "# download nltk packages\n",
    "# nltk.download()\n",
    "\n",
    "# working directory\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading data\n",
    "train = pd.read_csv(\"train.csv\", nrows = 10000)\n",
    "test = pd.read_csv(\"test.csv\", nrows = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "49f6b26a-9b0d-4b17-9541-07499497bf75",
    "_uuid": "5314745d9591b2f4d78ce2f0b5de47c26268a8ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    Yo bitch Ja Rule is more succesful then you'll...\n",
       "1    == From RfC == \\n\\n The title is fine as it is...\n",
       "2    \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3    :If you have a look back at the source, the in...\n",
       "4            I don't anonymously edit articles at all.\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying data\n",
    "train.comment_text.head()\n",
    "test.comment_text.head()\n",
    "len(train)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train.comment_text, train.iloc[:,2:8], test_size=0.3, random_state=19)\n",
    "X_test = test.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating function to normalize text\n",
    "def normalize(text):\n",
    "    # recognizing new line characters and tab spaces and substituting it with space\n",
    "    norm_text = re.sub(r'\\n|\\t', ' ', text)\n",
    "    # recognizing time values\n",
    "    norm_text = re.sub(r'[0-9]{1,2}:[0-9][0-9]', 'time_value', norm_text) # example 5:13pm and 05:13pm\n",
    "    # recognizing date values\n",
    "    norm_text = re.sub(r'\\d{1,4}[-/]\\d{1,2}[-/]\\d{1,4}', 'date_value', norm_text) # example 2018-03/05 and 04/03-2018\n",
    "    norm_text = re.sub(r'[0-9]{1,4}[ ,][A-Za-z]{3,10}[ ,][0-9]{1,4}', 'date_value', norm_text) # example 9 june 2009 and 9 June 2009\n",
    "    # substitute characters not required by nothing, removing unrequired characters\n",
    "    norm_text = re.sub(r'[^A-Za-z_ ]', ' ', norm_text)\n",
    "    # removing multiple space values\n",
    "    norm_text = re.sub(r' +', ' ', norm_text)\n",
    "    # removing trailing spaces from front and back and converting all text to lowercase\n",
    "    norm_text = norm_text.strip().lower()\n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating stemmer object of PorterStemmer function\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# writing stem_tokens function to perform stemming on tokens\n",
    "def stem_tokens(tokens, stemmer): # tokens example: ['today', 'is', 'a', 'good', 'day']\n",
    "    stemmed = [stemmer.stem(word) for word in tokens]\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# processing text as follows\n",
    "# tokenize words in each comment\n",
    "# remove stopwords or words upto lenght of 3 characters\n",
    "# stem words using the stem_tokens function we created above\n",
    "def text_process(text): # text is a single sentence; for example: 'today is a good day'\n",
    "    temp_tokens = word_tokenize(text)\n",
    "\n",
    "    # using alternative to removing stopwords of english\n",
    "    ## tokens = [word for word in temp_tokens if len(word) > 3]\n",
    "    \n",
    "    # removing english stopwords, code was commented to save computation time\n",
    "    nostop_tokens = [word for word in temp_tokens if word not in stopwords.words('english')]\n",
    "    \n",
    "    stems = stem_tokens(nostop_tokens, stemmer)\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lenght of stopword of english\n",
    "len(stopwords.words('english'))\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing training text to pass in count vectorizer\n",
    "corpus = []\n",
    "for text in X_train:\n",
    "    text = normalize(text)\n",
    "    text = text_process(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build Count Vectorizer, to convert a collection of text documents to a matrix of token counts\n",
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "X_train_counts = count_vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build TFIDF Transformer, to transform a count matrix to a normalized tf or tf-idf representation\n",
    "# tfidf - term frequency inverse document frequency\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verifing data\n",
    "# print(X_train_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verifing data\n",
    "# print(X_train_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  After  \\\n",
      "8098  edit anthoni hungerford dear phillip comment r...   \n",
      "3382  welcom wikipedia pleas stop insert unsourc lib...   \n",
      "5286                ye red link meet mo dabrl see chang   \n",
      "3693  hello submiss utrecht te deum jubil know nomin...   \n",
      "9616  song adapt worth song iron maiden movi heart d...   \n",
      "1818  lol lol serious bryanfrompalatin ip resolv col...   \n",
      "3687  thank welcom thank tom warm welcom see path cr...   \n",
      "3791  thank moonriddengirl wikidea sure excel lawyer...   \n",
      "6176  also tag page vkurka cur prev time_valu date_v...   \n",
      "925   wikipedia full fool take money make peopl work...   \n",
      "\n",
      "                                                 Before  \n",
      "8098  \"\\n\\n Editing of Anthony Hungerford \\n\\nDear P...  \n",
      "3382  Welcome to Wikipedia. Please stop inserting un...  \n",
      "5286  Yes, it was a red link which didn't meet MOS:D...  \n",
      "3693  Hello! Your submission of Utrecht Te Deum and ...  \n",
      "9616  \"\\n\\nsong adaptation\\nfor what it worthes ther...  \n",
      "1818  \"\\n\\n LOL \\n\\nLOL. Seriously, \"\"BryanFromPalat...  \n",
      "3687  Thanks for the welcome \\n\\nThanks Tom for the ...  \n",
      "3791  Thanks Moonriddengirl. Wikidea, I'm sure you'r...  \n",
      "6176  You also tagged my page, vkurka. (cur | prev) ...  \n",
      "925   Wikipedia is full of fools. Who takes money an...  \n"
     ]
    }
   ],
   "source": [
    "# checking how much text is transformed\n",
    "temp = pd.DataFrame({'Before': X_train, 'After': corpus})\n",
    "print(temp.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing validation text to pass in count vectorizer\n",
    "X_val_set = []\n",
    "for text in X_val:\n",
    "    text = normalize(text)\n",
    "    text = text_process(text)\n",
    "    X_val_set.append(text)\n",
    "\n",
    "# tranforming validation data using count vectorizer followed by tfidf transformer\n",
    "X_val_counts = count_vect.transform(X_val_set)\n",
    "X_val_tfidf = tfidf_transformer.transform(X_val_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing test text to pass in count vectorizer\n",
    "X_test_set = []\n",
    "for text in X_test:\n",
    "    text = normalize(text)\n",
    "    text = text_process(text)\n",
    "    X_test_set.append(text)\n",
    "\n",
    "# tranforming validation data using count vectorizer followed by tfidf transformer\n",
    "X_test_counts = count_vect.transform(X_test_set)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Singular Value Decomposition\n",
    "# Commented as using SVD decreased the estimation score\n",
    "# build Truncated SVD to reduce the dimensionality\n",
    "\n",
    "## svd=TruncatedSVD(n_components=100)\n",
    "## X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "## X_val_svd = svd.transform(X_val_tfidf)\n",
    "## X_test_svd = svd.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating dictionary to store prediction results\n",
    "result_test = dict()\n",
    "result_val = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__alpha': [0.001, 0.01, 0.1, 1.0, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of Multinomial Naive Bayes Classifier on Training Data: 1.000\n",
      "Accurary of Multinomial Naive Bayes Classifier on Validation Data: 0.825\n",
      "Grid best parameter (max. accuracy):  {'estimator__alpha': 0.1}\n",
      "Grid best score (accuracy):  0.848985648234\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes Model\n",
    "MNB_classifier = OneVsRestClassifier(MultinomialNB())\n",
    "grid_values = {'estimator__alpha': [0.001, 0.01, 0.1, 1.0, 10, 100]}\n",
    "MNB_model = GridSearchCV(MNB_classifier, param_grid = grid_values, scoring = 'roc_auc')\n",
    "MNB_model.fit(X_train_tfidf, y_train)\n",
    "print('Accurary of Multinomial Naive Bayes Classifier on Training Data: {:.3f}' .format(MNB_model.score(X_train_tfidf, y_train)))\n",
    "print('Accurary of Multinomial Naive Bayes Classifier on Validation Data: {:.3f}' .format(MNB_model.score(X_val_tfidf, y_val)))\n",
    "print('Grid best parameter (max. accuracy): ', MNB_model.best_params_)\n",
    "print('Grid best score (accuracy): ', MNB_model.best_score_)\n",
    "result_test['Multinomial_NB'] = MNB_model.predict(X_test_tfidf)\n",
    "result_val['Multinomial_NB'] = MNB_model.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([376,   0, 133,   0,  53,   0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial_NB result summary\n",
    "result_test['Multinomial_NB'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__alpha': [0.001, 0.01, 0.1, 1.0, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of Bernoulli Naive Bayes Classifier on Training Data: 1.000\n",
      "Accurary of Bernoulli Naive Bayes Classifier on Validation Data: 0.814\n",
      "Grid best parameter (max. accuracy):  {'estimator__alpha': 0.001}\n",
      "Grid best score (accuracy):  0.815762586966\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes Model\n",
    "BNB_classifier = OneVsRestClassifier(BernoulliNB())\n",
    "grid_values = {'estimator__alpha': [0.001, 0.01, 0.1, 1.0, 10, 100]}\n",
    "BNB_model = GridSearchCV(BNB_classifier, param_grid = grid_values, scoring = 'roc_auc')\n",
    "BNB_model.fit(X_train_tfidf, y_train)\n",
    "print('Accurary of Bernoulli Naive Bayes Classifier on Training Data: {:.3f}' .format(BNB_model.score(X_train_tfidf, y_train)))\n",
    "print('Accurary of Bernoulli Naive Bayes Classifier on Validation Data: {:.3f}' .format(BNB_model.score(X_val_tfidf, y_val)))\n",
    "print('Grid best parameter (max. accuracy): ', BNB_model.best_params_)\n",
    "print('Grid best score (accuracy): ', BNB_model.best_score_)\n",
    "result_test['Bernoulli_NB'] = BNB_model.predict(X_test_tfidf)\n",
    "result_val['Bernoulli_NB'] = BNB_model.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3770, 2457, 3265, 2089, 3453, 2447])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernoulli_NB result summary\n",
    "result_test['Bernoulli_NB'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__C': [0.3, 1.0, 30.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of Logistic Regression Classifier on Training Data: 1.000\n",
      "Accurary of Logistic Regression Classifier on Validation Data: 0.971\n",
      "Grid best parameter (max. accuracy):  {'estimator__C': 30.0}\n",
      "Grid best score (accuracy):  0.953124843436\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "log_model = OneVsRestClassifier(LogisticRegression())\n",
    "#log_model.get_params().keys()\n",
    "grid_values = {'estimator__C': [0.3, 1.0, 30.0]}\n",
    "log_grid = GridSearchCV(log_model, param_grid = grid_values, scoring = 'roc_auc')\n",
    "log_grid.fit(X_train_tfidf, y_train)\n",
    "print('Accurary of Logistic Regression Classifier on Training Data: {:.3f}' .format(log_grid.score(X_train_tfidf, y_train)))\n",
    "print('Accurary of Logistic Regression Classifier on Validation Data: {:.3f}' .format(log_grid.score(X_val_tfidf, y_val)))\n",
    "print('Grid best parameter (max. accuracy): ', log_grid.best_params_)\n",
    "print('Grid best score (accuracy): ', log_grid.best_score_)\n",
    "result_test['Logistic_Regression'] = log_grid.predict(X_test_tfidf)\n",
    "result_val['Logistic_Regression'] = log_grid.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1269,   83,  712,    1,  663,   59])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic_Regression result summary\n",
    "result_test['Logistic_Regression'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__C': [0.3, 1.0, 30.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of SVM Classifier on Training Data: 1.000\n",
      "Accurary of SVM Classifier on Validation Data: 0.953\n",
      "Grid best parameter (max. accuracy):  {'estimator__C': 0.3}\n",
      "Grid best score (accuracy):  0.939056090018\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier Model\n",
    "grid_values = {'estimator__C': [0.3, 1.0, 30.0]}\n",
    "svm_model = OneVsRestClassifier(SVC(kernel = 'linear'))\n",
    "svm_grid = GridSearchCV(svm_model, param_grid = grid_values, scoring = 'roc_auc')\n",
    "svm_grid.fit(X_train_tfidf, y_train)\n",
    "print('Accurary of SVM Classifier on Training Data: {:.3f}' .format(svm_grid.score(X_train_tfidf, y_train)))\n",
    "print('Accurary of SVM Classifier on Validation Data: {:.3f}' .format(svm_grid.score(X_val_tfidf, y_val)))\n",
    "print('Grid best parameter (max. accuracy): ', svm_grid.best_params_)\n",
    "print('Grid best score (accuracy): ', svm_grid.best_score_)\n",
    "result_test['SVM_Classifier'] = svm_grid.predict(X_test_tfidf)\n",
    "result_val['SVM_Classifier'] = svm_grid.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([592,   0, 455,   0, 304,   0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM_Classifier result summary\n",
    "result_test['SVM_Classifier'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Toxic Cases using Multinomial Naive Bayes Model: 562.00\n",
      "Number of Toxic Cases using Bernoulli Naive Bayes Model: 17481.00\n",
      "Number of Toxic Cases using Logistic Regression Classifier Model: 2787.00\n",
      "Number of Toxic Cases using SVM Classifier Model: 1351.00\n",
      "\n",
      "Total Number of Comments for which we made Predictions: 10000.00\n",
      "\n",
      "Total Number of Positive Cases in Training Data (Training + Validation): 2210.00\n",
      "Total Number of Comments in Training Data (Training + Validation): 10000.00\n",
      "Number of Toxic Cases using SVM Classifier Model: 406.00\n"
     ]
    }
   ],
   "source": [
    "# how many positive cases, i.e toxic cases we recognized for each model?\n",
    "print('Number of Toxic Cases using Multinomial Naive Bayes Model: {:.2f}' .format(result_test['Multinomial_NB'].sum()))\n",
    "print('Number of Toxic Cases using Bernoulli Naive Bayes Model: {:.2f}' .format(result_test['Bernoulli_NB'].sum()))\n",
    "print('Number of Toxic Cases using Logistic Regression Classifier Model: {:.2f}' .format(result_test['Logistic_Regression'].sum()))\n",
    "print('Number of Toxic Cases using SVM Classifier Model: {:.2f}' .format(result_test['SVM_Classifier'].sum()))\n",
    "\n",
    "# predicted for how many comments?\n",
    "print('\\nTotal Number of Comments for which we made Predictions: {:.2f}' .format(len(X_test)))\n",
    "\n",
    "# number of positive cases in training data and length of training data, includes validation data\n",
    "print('\\nTotal Number of Positive Cases in Training Data (Training + Validation): {:.2f}' .format(train.iloc[:,2:8].sum(axis=0).sum()))\n",
    "print('Total Number of Comments in Training Data (Training + Validation): {:.2f}' .format(len(X_train)+len(X_val)))\n",
    "\n",
    "# number of predicted positive cases in training data using SVM model\n",
    "print('Number of Toxic Cases using SVM Classifier Model: {:.2f}' .format(svm_grid.predict(X_train_tfidf).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing results of SVM Classifier as our result\n",
    "y_test = result_test['SVM_Classifier']\n",
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...      1   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...      0   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...      0   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...      0   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining final results with the original test data set\n",
    "output = pd.DataFrame(y_test, columns = train.columns[2:8], index = test.index)\n",
    "output = pd.concat([test, output], axis=1)\n",
    "\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifing data\n",
    "X_train_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-78bdc2795467>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# verifing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;31m##############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# verifing data\n",
    "X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>0e70fb3a97f7514e</td>\n",
       "      <td>::::::: Is there any problem if we wait until ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>00d08307c9439df8</td>\n",
       "      <td>This dude sucks donkey dick</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>04a5305ec9e681b3</td>\n",
       "      <td>== Pictures == \\n\\n Do all of them have to hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>075bd9b9449da9a0</td>\n",
       "      <td>I believe other publications also carried this...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>014c2d8307d7ed7b</td>\n",
       "      <td>D. Hinmon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9960</th>\n",
       "      <td>109fd35f7e6b65c9</td>\n",
       "      <td>Is Haham hanuka a muslim islamist rag-head? cu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>005bb8c85ea8239c</td>\n",
       "      <td>on February 21, 2015.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0043c91b8619691c</td>\n",
       "      <td>: I came across the lawsuit info while I was d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>0d3192fd7e1ad353</td>\n",
       "      <td>Believe me, there not...(WHO THE HECK CARES AB...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>09a367d86029f503</td>\n",
       "      <td>s   sdfgsfdg        ockpuppet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>07a88879d68b3dbf</td>\n",
       "      <td>\" \\n\\n == Taiwan street peddlers today? == \\n\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>02915e48ce8c29d1</td>\n",
       "      <td>what do you need help with?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>03a3e672cc08834d</td>\n",
       "      <td>\" March 2014 (UTC) \\n :::: And the US Governme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>05466f2b0e81c6cd</td>\n",
       "      <td>== Requested move == \\n\\n  \\n * Thoma I → Mar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>0f8f254ec4baa813</td>\n",
       "      <td>==Nicky Evans== \\n Please do not revert good f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383</th>\n",
       "      <td>0fabe620dc809e32</td>\n",
       "      <td>fuck lake ridge!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>007cbba20a6abc0b</td>\n",
       "      <td>\" \\n\\n == Why is this article not called \"\"Rep...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>0e9714984bb0a5aa</td>\n",
       "      <td>== Callow Park == \\n\\n hi victuallers please c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>07eec1557eb00645</td>\n",
       "      <td>=Proposed merge= \\n ISTM that these two articl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6787</th>\n",
       "      <td>0b6f229fb891bde1</td>\n",
       "      <td>\" \\n\\n == Disputed changes feedback request ==...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                       comment_text  \\\n",
       "8612  0e70fb3a97f7514e  ::::::: Is there any problem if we wait until ...   \n",
       "499   00d08307c9439df8                        This dude sucks donkey dick   \n",
       "2691  04a5305ec9e681b3  == Pictures == \\n\\n Do all of them have to hav...   \n",
       "4323  075bd9b9449da9a0  I believe other publications also carried this...   \n",
       "785   014c2d8307d7ed7b                                          D. Hinmon   \n",
       "9960  109fd35f7e6b65c9  Is Haham hanuka a muslim islamist rag-head? cu...   \n",
       "209   005bb8c85ea8239c                              on February 21, 2015.   \n",
       "168   0043c91b8619691c  : I came across the lawsuit info while I was d...   \n",
       "7851  0d3192fd7e1ad353  Believe me, there not...(WHO THE HECK CARES AB...   \n",
       "5710  09a367d86029f503                      s   sdfgsfdg        ockpuppet   \n",
       "4509  07a88879d68b3dbf  \" \\n\\n == Taiwan street peddlers today? == \\n\\...   \n",
       "1528  02915e48ce8c29d1                        what do you need help with?   \n",
       "2114  03a3e672cc08834d  \" March 2014 (UTC) \\n :::: And the US Governme...   \n",
       "3067  05466f2b0e81c6cd  == Requested move == \\n\\n  \\n * Thoma I → Mar ...   \n",
       "9322  0f8f254ec4baa813  ==Nicky Evans== \\n Please do not revert good f...   \n",
       "9383  0fabe620dc809e32                                   fuck lake ridge!   \n",
       "285   007cbba20a6abc0b  \" \\n\\n == Why is this article not called \"\"Rep...   \n",
       "8707  0e9714984bb0a5aa  == Callow Park == \\n\\n hi victuallers please c...   \n",
       "4675  07eec1557eb00645  =Proposed merge= \\n ISTM that these two articl...   \n",
       "6787  0b6f229fb891bde1  \" \\n\\n == Disputed changes feedback request ==...   \n",
       "\n",
       "      toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "8612      0             0        0       0       0              0  \n",
       "499       1             0        1       0       0              0  \n",
       "2691      1             0        1       0       1              0  \n",
       "4323      0             0        0       0       0              0  \n",
       "785       0             0        0       0       0              0  \n",
       "9960      0             0        0       0       0              0  \n",
       "209       0             0        0       0       0              0  \n",
       "168       0             0        0       0       0              0  \n",
       "7851      0             0        0       0       0              0  \n",
       "5710      0             0        0       0       0              0  \n",
       "4509      0             0        0       0       0              0  \n",
       "1528      0             0        0       0       0              0  \n",
       "2114      0             0        0       0       0              0  \n",
       "3067      0             0        0       0       0              0  \n",
       "9322      0             0        0       0       0              0  \n",
       "9383      1             0        1       0       1              0  \n",
       "285       0             0        0       0       0              0  \n",
       "8707      0             0        0       0       0              0  \n",
       "4675      0             0        0       0       0              0  \n",
       "6787      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifing data\n",
    "output.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                09f4b7014a35f365\n",
       "comment_text     ==Gay Cowboys== \\n\\n My thoughts about this: G...\n",
       "toxic                                                            0\n",
       "severe_toxic                                                     0\n",
       "obscene                                                          0\n",
       "threat                                                           0\n",
       "insult                                                           0\n",
       "identity_hate                                                    0\n",
       "Name: 5902, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'==Gay Cowboys== \\n\\n My thoughts about this: Gay cowboys humping on bareback mountain. There I said. I feel better now. Now you all can criticise me as homophobic and vandalise my talk page. I think ill say it again...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...GAY COWBOYS...'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifing select random case, as per index from above code chunk\n",
    "output.iloc[5902,:]\n",
    "output.comment_text[5902]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "3670      0             0        0       0       0              0\n",
       "3415      0             0        0       0       0              0\n",
       "1301      0             0        0       0       0              0\n",
       "1355      1             0        0       0       1              0\n",
       "7303      0             0        0       0       0              0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifing data\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            679\n",
       "severe_toxic      73\n",
       "obscene          354\n",
       "threat            21\n",
       "insult           345\n",
       "identity_hate     66\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "toxic            292\n",
       "severe_toxic      28\n",
       "obscene          173\n",
       "threat            12\n",
       "insult           149\n",
       "identity_hate     18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "toxic            592\n",
       "severe_toxic       0\n",
       "obscene          455\n",
       "threat             0\n",
       "insult           304\n",
       "identity_hate      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick summary for training, validation and test set respectively\n",
    "# this shows the balance in results using SVM model in comparison to training data\n",
    "y_train.sum(axis=0)\n",
    "y_val.sum(axis=0)\n",
    "output.iloc[:,2:8].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.90      1.00      0.95      2708\n",
      "   negative       0.00      0.00      0.00       292\n",
      "\n",
      "avg / total       0.81      0.90      0.86      3000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.94      0.89      0.91      2708\n",
      "   negative       0.30      0.44      0.35       292\n",
      "\n",
      "avg / total       0.87      0.84      0.86      3000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.90      1.00      0.95      2708\n",
      "   negative       1.00      0.02      0.04       292\n",
      "\n",
      "avg / total       0.91      0.90      0.86      3000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.90      1.00      0.95      2708\n",
      "   negative       0.00      0.00      0.00       292\n",
      "\n",
      "avg / total       0.81      0.90      0.86      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yang\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# precision recall f1-score report\n",
    "print(metrics.classification_report(y_val.toxic, result_val['Multinomial_NB'][:,1], target_names = [\"positive\", \"negative\"]))\n",
    "print(metrics.classification_report(y_val.toxic, result_val['Bernoulli_NB'][:,1], target_names = [\"positive\", \"negative\"]))\n",
    "print(metrics.classification_report(y_val.toxic, result_val['Logistic_Regression'][:,1], target_names = [\"positive\", \"negative\"]))\n",
    "print(metrics.classification_report(y_val.toxic, result_val['SVM_Classifier'][:,1], target_names = [\"positive\", \"negative\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a object with final output of predictions on the test data set\n",
    "final_output = output.drop(['comment_text'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing the output object to a csv file\n",
    "final_output.to_csv('submission_project.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
